#!/usr/bin/env python3
"""
WebArena API Generator

This script extracts API documentation from WebArena benchmark files and
generates Python tools using ToolFactory's extractor and generator.
"""

import os
import sys
import json
import re
import shutil
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Import ToolFactory components
from extractor.api_json_extractor import Extractor
from extractor.api_code_generator import Generator

# Define paths
SCRIPT_DIR = Path(__file__).resolve().parent
WEBARENA_API_PATH = SCRIPT_DIR / "evaluation" / "API-Based-Agent" / "evaluation" / "webarena" / "api"
OUTPUT_PATH = SCRIPT_DIR / "webarena_tools"
TEMP_PATH = SCRIPT_DIR / "temp_api_docs"

class WebArenaAPIGenerator:
    """
    WebArena API Generator
    
    Extracts API documentation from WebArena benchmark files and
    generates Python tools using ToolFactory's extractor and generator.
    """
    
    def __init__(self):
        """Initialize the WebArena API Generator"""
        # Check if OpenAI API key is set
        if not os.environ.get("OPENAI_API_KEY"):
            print("Error: OPENAI_API_KEY environment variable is not set.")
            print("Please set your OpenAI API key in the .env file.")
            sys.exit(1)
            
        self.extractor = Extractor()
        self.generator = Generator()
        
        # Create output directory if it doesn't exist
        os.makedirs(OUTPUT_PATH, exist_ok=True)
        
        # Create __init__.py file in output directory
        init_file = OUTPUT_PATH / "__init__.py"
        if not os.path.exists(init_file):
            with open(init_file, 'w') as f:
                f.write('"""WebArena API tools generated by ToolFactory"""')
        
        # Create temp directory if it doesn't exist
        os.makedirs(TEMP_PATH, exist_ok=True)
    
    def generate_gitlab_api_tools(self):
        """Generate GitLab API tools"""
        print("Generating GitLab API tools...")
        
        gitlab_api_file = WEBARENA_API_PATH / "gitlab_api_list.json"
        if not os.path.exists(gitlab_api_file):
            print(f"GitLab API file not found: {gitlab_api_file}")
            return False
        
        # Load GitLab API documentation
        with open(gitlab_api_file, 'r') as f:
            gitlab_data = json.load(f)
        
        # Convert GitLab JSON format to text description for the extractor
        gitlab_text = "# GitLab API Documentation\n\n"
        for endpoint_key, description in gitlab_data.items():
            parts = endpoint_key.split(' ', 1)
            if len(parts) != 2:
                continue
                
            method, path = parts
            gitlab_text += f"## {method.upper()} {path}\n\n"
            gitlab_text += f"{description}\n\n"
        
        # Use the extractor to process the API documentation
        os.makedirs(TEMP_PATH / "gitlab", exist_ok=True)
        temp_file = TEMP_PATH / "gitlab" / "gitlab_api.md"
        
        # Write the markdown content to a temporary file
        with open(temp_file, 'w') as f:
            f.write(gitlab_text)
        
        # Create a custom parser for the markdown file
        def markdown_parser(file_path):
            with open(file_path, 'r') as f:
                return f.read()
        
        # Extract API details using OpenAI through the extractor
        api_json = self.extractor.extract_api_json(
            str(temp_file),
            file_parser=markdown_parser
        )
        
        # Save the API JSON to a file
        api_json_file = TEMP_PATH / "gitlab" / "gitlab_api.json"
        with open(api_json_file, 'w') as f:
            f.write(api_json)
        
        # Parse the API JSON string
        api_json_obj = json.loads(api_json)
        
        # Set the base URL for all endpoints
        for endpoint in api_json_obj["endpoints"]:
            if endpoint["url"] == "missing":
                endpoint["url"] = f"http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:8023{endpoint['url']}"
        
        # Generate API tools
        output_dir = OUTPUT_PATH / "gitlab"
        os.makedirs(output_dir, exist_ok=True)
        
        # Create __init__.py file
        with open(output_dir / "__init__.py", 'w') as f:
            f.write('"""GitLab API tools generated by ToolFactory"""')
        
        # Generate code for each endpoint
        for endpoint in api_json_obj["endpoints"]:
            endpoint_json = {"title": api_json_obj["title"], "endpoints": [endpoint]}
            endpoint_json_str = json.dumps(endpoint_json)
            self.generator.generate_from_api_json_and_save(
                endpoint_json_str, 
                str(output_dir),
                {"base_url": "", "url_in_param": False}
            )
        
        print(f"Successfully generated GitLab API tools at: {output_dir}")
        return True
    
    def generate_reddit_api_tools(self):
        """Generate Reddit API tools"""
        print("Generating Reddit API tools...")
        
        reddit_api_file = WEBARENA_API_PATH / "reddit.md"
        if not os.path.exists(reddit_api_file):
            print(f"Reddit API file not found: {reddit_api_file}")
            return False
        
        # Create a temp directory for Reddit API
        os.makedirs(TEMP_PATH / "reddit", exist_ok=True)
        
        # Create a custom parser for the markdown file
        def markdown_parser(file_path):
            with open(file_path, 'r') as f:
                return f.read()
        
        # Extract API details using OpenAI through the extractor
        api_json = self.extractor.extract_api_json(
            str(reddit_api_file),
            file_parser=markdown_parser
        )
        
        # Save the API JSON to a file
        api_json_file = TEMP_PATH / "reddit" / "reddit_api.json"
        with open(api_json_file, 'w') as f:
            f.write(api_json)
        
        # Parse the API JSON string
        api_json_obj = json.loads(api_json)
        
        # Set the base URL for all endpoints
        for endpoint in api_json_obj["endpoints"]:
            if endpoint["url"] == "missing":
                endpoint["url"] = f"http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:9999{endpoint['url']}"
        
        # Generate API tools
        output_dir = OUTPUT_PATH / "reddit"
        os.makedirs(output_dir, exist_ok=True)
        
        # Create __init__.py file
        with open(output_dir / "__init__.py", 'w') as f:
            f.write('"""Reddit API tools generated by ToolFactory"""')
        
        # Generate code for each endpoint
        for endpoint in api_json_obj["endpoints"]:
            endpoint_json = {"title": api_json_obj["title"], "endpoints": [endpoint]}
            endpoint_json_str = json.dumps(endpoint_json)
            self.generator.generate_from_api_json_and_save(
                endpoint_json_str, 
                str(output_dir),
                {"base_url": "", "url_in_param": False}
            )
        
        print(f"Successfully generated Reddit API tools at: {output_dir}")
        return True
    
    def generate_shopping_api_tools(self):
        """Generate Shopping API tools"""
        print("Generating Shopping API tools...")
        
        shopping_api_file = WEBARENA_API_PATH / "shopping-admin-summary.json"
        if not os.path.exists(shopping_api_file):
            print(f"Shopping API file not found: {shopping_api_file}")
            return False
        
        # Load Shopping API documentation
        with open(shopping_api_file, 'r') as f:
            shopping_data = json.load(f)
        
        # Convert Shopping JSON format to text description for the extractor
        shopping_text = "# Shopping API Documentation\n\n"
        for endpoint_key, description in shopping_data.items():
            parts = endpoint_key.split(' ', 1)
            if len(parts) != 2:
                continue
                
            method, path = parts
            shopping_text += f"## {method.upper()} {path}\n\n"
            shopping_text += f"{description}\n\n"
        
        # Use the extractor to process the API documentation
        os.makedirs(TEMP_PATH / "shopping", exist_ok=True)
        temp_file = TEMP_PATH / "shopping" / "shopping_api.md"
        
        # Write the markdown content to a temporary file
        with open(temp_file, 'w') as f:
            f.write(shopping_text)
        
        # Create a custom parser for the markdown file
        def markdown_parser(file_path):
            with open(file_path, 'r') as f:
                return f.read()
        
        # Extract API details using OpenAI through the extractor
        api_json = self.extractor.extract_api_json(
            str(temp_file),
            file_parser=markdown_parser
        )
        
        # Save the API JSON to a file
        api_json_file = TEMP_PATH / "shopping" / "shopping_api.json"
        with open(api_json_file, 'w') as f:
            f.write(api_json)
        
        # Parse the API JSON string
        api_json_obj = json.loads(api_json)
        
        # Set the base URL for all endpoints
        for endpoint in api_json_obj["endpoints"]:
            if endpoint["url"] == "missing":
                endpoint["url"] = f"http://ec2-18-219-239-190.us-east-2.compute.amazonaws.com:7770/rest/default{endpoint['url']}"
        
        # Generate API tools
        output_dir = OUTPUT_PATH / "shopping"
        os.makedirs(output_dir, exist_ok=True)
        
        # Create __init__.py file
        with open(output_dir / "__init__.py", 'w') as f:
            f.write('"""Shopping API tools generated by ToolFactory"""')
        
        # Generate code for each endpoint
        for endpoint in api_json_obj["endpoints"]:
            endpoint_json = {"title": api_json_obj["title"], "endpoints": [endpoint]}
            endpoint_json_str = json.dumps(endpoint_json)
            self.generator.generate_from_api_json_and_save(
                endpoint_json_str, 
                str(output_dir),
                {"base_url": "", "url_in_param": False}
            )
        
        print(f"Successfully generated Shopping API tools at: {output_dir}")
        return True
    
    def generate_parameter_dictionary(self):
        """Generate parameter dictionary for suggestions"""
        print("Generating parameter dictionary...")
        
        parameter_dict = {}
        
        # Collect parameters from all APIs
        for api_dir in ["gitlab", "reddit", "shopping"]:
            api_path = OUTPUT_PATH / api_dir
            if not os.path.exists(api_path):
                continue
            
            # Process all Python files in API directory
            for py_file in api_path.glob("*.py"):
                if py_file.name == "__init__.py":
                    continue
                
                # Read Python file
                with open(py_file, 'r') as f:
                    content = f.read()
                
                # Extract function name and parameters
                func_match = re.search(r"def\s+(\w+)\s*\((.*?)\):", content, re.DOTALL)
                if func_match:
                    func_name = func_match.group(1)
                    params_text = func_match.group(2)
                    
                    # Process parameters
                    params = []
                    for param in params_text.split(","):
                        param = param.strip()
                        if not param or param == "self":
                            continue
                        
                        # Extract parameter name without default value
                        if "=" in param:
                            param_name = param.split("=")[0].strip()
                        else:
                            param_name = param.strip()
                        
                        params.append(param_name)
                        
                        # Add parameter to dictionary with suggestions
                        parameter_key = f"{api_dir}.{func_name}.{param_name}"
                        parameter_dict[parameter_key] = {
                            "suggestions": []
                        }
                        
                        # Add default suggestions based on parameter name
                        if param_name == "id" or param_name.endswith("_id"):
                            parameter_dict[parameter_key]["suggestions"] = ["1", "2", "3"]
                        elif param_name == "name" or param_name.endswith("_name"):
                            parameter_dict[parameter_key]["suggestions"] = ["example", "test", "demo"]
                        elif param_name == "limit":
                            parameter_dict[parameter_key]["suggestions"] = ["5", "10", "25"]
        
        # Save parameter dictionary
        param_dict_file = OUTPUT_PATH / "parameter_dictionary.json"
        with open(param_dict_file, 'w') as f:
            json.dump(parameter_dict, f, indent=2)
        
        print(f"Successfully generated parameter dictionary at: {param_dict_file}")
        return True
    
    def cleanup(self):
        """Clean up temporary files"""
        if os.path.exists(TEMP_PATH):
            shutil.rmtree(TEMP_PATH)
            print(f"Cleaned up temporary files at: {TEMP_PATH}")
    
    def run(self):
        """Run the WebArena API Generator"""
        print(f"WebArena API Generator")
        print(f"WebArena API Path: {WEBARENA_API_PATH}")
        print(f"Output Path: {OUTPUT_PATH}")
        print(f"Temporary Path: {TEMP_PATH}")
        
        # Check if WebArena API directory exists
        if not os.path.exists(WEBARENA_API_PATH):
            print(f"WebArena API directory not found: {WEBARENA_API_PATH}")
            return False
        
        # Generate API tools
        gitlab_success = self.generate_gitlab_api_tools()
        reddit_success = self.generate_reddit_api_tools()
        shopping_success = self.generate_shopping_api_tools()
        
        # Generate parameter dictionary
        if gitlab_success or reddit_success or shopping_success:
            self.generate_parameter_dictionary()
        
        # Clean up
        self.cleanup()
        
        # Summary
        print("\nSummary:")
        print(f"GitLab API: {'Success' if gitlab_success else 'Failed'}")
        print(f"Reddit API: {'Success' if reddit_success else 'Failed'}")
        print(f"Shopping API: {'Success' if shopping_success else 'Failed'}")
        
        return True

if __name__ == "__main__":
    generator = WebArenaAPIGenerator()
    generator.run() 